{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "authorship_tag": "ABX9TyN2TdM6I7w7GOK3MN9ARHVF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccitChun/1081ML/blob/main/one_cnn_ks3_pool4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install thop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwC2b7viXKHt",
        "outputId": "0c2fd3cb-45ab-452e-a375-9edc698effea"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: thop in /usr/local/lib/python3.10/dist-packages (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from thop) (2.3.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->thop) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2024.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->thop) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->thop) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yC-WUJQTnfG5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import os\n",
        "from torchvision import datasets\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from thop import profile  # for calculating FLOPS and parameters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "os.getcwd()\n",
        "os.chdir(\"/content/drive/MyDrive\") #更改路徑\n",
        "os.listdir()\n",
        "folders = os.listdir('./data2')\n",
        "folders.sort()\n",
        "data_path = '/content/drive/MyDrive/data2'\n",
        "file_paths = []\n",
        "labels = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6XgZp1enyXt",
        "outputId": "8cea70d3-608d-4833-b57a-92715c552dc0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, file_paths, labels, transform=None):\n",
        "        self.file_paths = file_paths# 存儲圖像文件路徑的列表\n",
        "        self.labels = labels # 與圖像對應的標籤列表\n",
        "        self.transform = transform # 可選的圖像變換（例如數據增強）\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths) # 返回數據集中的圖像總數\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.file_paths[idx]  # 獲取索引為idx的圖像路徑\n",
        "        image = Image.open(img_path).convert('RGB') # 打開圖像並確保它是RGB格式\n",
        "        label = self.labels[idx] # 獲取相應的標籤\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image) # 如果指定了轉換，則應用它\n",
        "\n",
        "        return image, label # 返回圖像和標籤的元組\n",
        "\n",
        "# Setup transformations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128),interpolation=Image.BILINEAR), # 將圖像大小調整為224x224像素\n",
        "   # transforms.RandomHorizontalFlip(), # 隨機水平翻轉圖像（數據增強）\n",
        "    transforms.ToTensor(), # 將圖像轉換為PyTorch張量\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),  # 歸一化圖像\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128), interpolation=Image.BILINEAR),  # 同樣將圖像大小調整為224x224像素\n",
        "    transforms.ToTensor(), # 將圖像轉換為PyTorch張量\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), # 同樣歸一化圖像\n",
        "])"
      ],
      "metadata": {
        "id": "vZojhepJoFaH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for folder_name in os.listdir(data_path):\n",
        "    folder_path = os.path.join(data_path, folder_name)\n",
        "    if os.path.isdir(folder_path):\n",
        "        for file_name in os.listdir(folder_path):\n",
        "            file_paths.append(os.path.join(folder_path, file_name))\n",
        "            labels.append(folder_name)"
      ],
      "metadata": {
        "id": "fVBYCBasoOCX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the lightweight CNN\n",
        "class LightweightCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(LightweightCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 10, kernel_size=3, padding='same')\n",
        "        self.pool1 = nn.MaxPool2d(4)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(10 * 32 * 32, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "jnr0a8e9nqiy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to numerical values\n",
        "label_to_index = {label: idx for idx, label in enumerate(sorted(set(labels)))}\n",
        "labels = [label_to_index[label] for label in labels]"
      ],
      "metadata": {
        "id": "049FCfifoQO1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "train_files, test_files, train_labels, test_labels = train_test_split(file_paths, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "train_dataset = MyDataset(train_files, train_labels, transform=train_transform)\n",
        "test_dataset = MyDataset(test_files, test_labels, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ],
      "metadata": {
        "id": "oY1o1zMmoTUn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = LightweightCNN(num_classes=len(label_to_index)).to(device)"
      ],
      "metadata": {
        "id": "g2ONFrjooYTW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "sq0L7YFIoZXm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate performance metrics\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    return precision, recall, f1"
      ],
      "metadata": {
        "id": "-hWCDD9qWKMQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and evaluation function\n",
        "def train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, num_epochs=10, device='cuda'):\n",
        "    model.to(device)\n",
        "\n",
        "    # Calculate FLOPS and parameters\n",
        "    input_tensor = torch.randn(1, 3, 128, 128).to(device)\n",
        "    flops, params = profile(model, inputs=(input_tensor, ))\n",
        "    flops_m = flops / 10**6\n",
        "    params_m = params / 10**6\n",
        "    print(f'FLOPS: {flops_m:.6f} MFLOPs, Parameters: {params_m:.6f} M')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss, total_correct = 0, 0\n",
        "        y_true, y_pred = [], []\n",
        "\n",
        "        # Iterate over the training data\n",
        "        for images, labels in tqdm(train_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(outputs.argmax(1).cpu().numpy())\n",
        "\n",
        "        train_loss = total_loss / len(train_loader.dataset)\n",
        "        train_accuracy = total_correct / len(train_loader.dataset)\n",
        "        train_precision, train_recall, train_f1 = calculate_metrics(y_true, y_pred)\n",
        "\n",
        "        model.eval()\n",
        "        total_loss, total_correct = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                total_loss += loss.item()\n",
        "                total_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "                y_true.extend(labels.cpu().numpy())\n",
        "                y_pred.extend(outputs.argmax(1).cpu().numpy())\n",
        "\n",
        "        test_loss = total_loss / len(test_loader.dataset)\n",
        "        test_accuracy = total_correct / len(test_loader.dataset)\n",
        "        test_precision, test_recall, test_f1 = calculate_metrics(y_true, y_pred)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '\n",
        "           f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, '\n",
        "           f'Test Precision: {test_precision:.4f}, Test Recall: {test_recall:.4f}, Test F1: {test_f1:.4f}')"
      ],
      "metadata": {
        "id": "kzk2ArZ_ocRO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, num_epochs=5, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7iYSQl2ohQG",
        "outputId": "ac2ba4a2-3909-4848-ebe2-896c39eb00c1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "FLOPS: 4.454400 MFLOPs, Parameters: 0.031003 M\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Train Loss: 0.0107, Train Accuracy: 0.8819, Test Loss: 0.0046, Test Accuracy: 0.9464, Test Precision: 0.8942, Test Recall: 0.8948, Test F1: 0.8941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 122/122 [01:15<00:00,  1.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5, Train Loss: 0.0027, Train Accuracy: 0.9706, Test Loss: 0.0017, Test Accuracy: 0.9866, Test Precision: 0.9738, Test Recall: 0.9738, Test F1: 0.9738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 122/122 [01:16<00:00,  1.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5, Train Loss: 0.0017, Train Accuracy: 0.9801, Test Loss: 0.0014, Test Accuracy: 0.9897, Test Precision: 0.9820, Test Recall: 0.9821, Test F1: 0.9820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 122/122 [01:15<00:00,  1.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5, Train Loss: 0.0011, Train Accuracy: 0.9887, Test Loss: 0.0012, Test Accuracy: 0.9897, Test Precision: 0.9889, Test Recall: 0.9889, Test F1: 0.9889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 122/122 [01:16<00:00,  1.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5, Train Loss: 0.0012, Train Accuracy: 0.9869, Test Loss: 0.0014, Test Accuracy: 0.9866, Test Precision: 0.9868, Test Recall: 0.9868, Test F1: 0.9868\n"
          ]
        }
      ]
    }
  ]
}